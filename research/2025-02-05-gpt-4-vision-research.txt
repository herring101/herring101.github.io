3:I[9261,[],""]
5:I[6675,[],""]
6:I[8379,["765","static/chunks/765-9a51a052c0b92136.js","605","static/chunks/605-4a7004ddde8f7487.js","887","static/chunks/887-f00c177c05ba72ba.js","185","static/chunks/app/layout-e44ec4ebe3a575a2.js"],"Providers"]
7:I[5861,["765","static/chunks/765-9a51a052c0b92136.js","605","static/chunks/605-4a7004ddde8f7487.js","887","static/chunks/887-f00c177c05ba72ba.js","185","static/chunks/app/layout-e44ec4ebe3a575a2.js"],"MainNav"]
4:["slug","2025-02-05-gpt-4-vision-research","d"]
0:["sINZ3LfkOSb8c3s1jZWdK",[[["",{"children":["research",{"children":[["slug","2025-02-05-gpt-4-vision-research","d"],{"children":["__PAGE__?{\"slug\":\"2025-02-05-gpt-4-vision-research\"}",{}]}]}]},"$undefined","$undefined",true],["",{"children":["research",{"children":[["slug","2025-02-05-gpt-4-vision-research","d"],{"children":["__PAGE__",{},["$L1",["$","article",null,{"className":"container mx-auto py-8 max-w-4xl","children":[["$","div",null,{"className":"mb-8","children":[["$","h1",null,{"className":"text-4xl font-bold mb-4","children":"GPT-4 Visionを用いた視覚的理解の研究"}],["$","div",null,{"className":"flex items-center gap-4 mb-4","children":[["$","time",null,{"className":"text-muted-foreground","children":"2025/2/5"}],["$","div",null,{"className":"flex gap-2 flex-wrap","children":[["$","div",null,{"className":"inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80","children":"GPT-4"}],["$","div",null,{"className":"inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80","children":"Computer Vision"}],["$","div",null,{"className":"inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80","children":"Deep Learning"}],["$","div",null,{"className":"inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80","children":"OpenAI"}]]}]]}],["$","p",null,{"className":"text-xl text-muted-foreground","children":"GPT-4 Visionの視覚的理解能力と応用可能性について深く掘り下げた研究"}]]}],["$","div",null,{"className":"prose prose-lg dark:prose-invert max-w-none","children":"$L2"}]]}],null]]},["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children","research","children","$4","children"],"loading":"$undefined","loadingStyles":"$undefined","loadingScripts":"$undefined","hasLoading":false,"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","styles":null}]]},["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children","research","children"],"loading":"$undefined","loadingStyles":"$undefined","loadingScripts":"$undefined","hasLoading":false,"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","styles":null}]]},[null,["$","html",null,{"lang":"en","suppressHydrationWarning":true,"children":["$","body",null,{"className":"__variable_d65c78 __variable_43fb55 min-h-screen bg-background font-sans antialiased","children":["$","$L6",null,{"children":["$","div",null,{"className":"relative flex min-h-screen flex-col","children":[["$","header",null,{"className":"sticky top-0 z-50 w-full border-b bg-background/95 backdrop-blur supports-[backdrop-filter]:bg-background/60","children":["$","div",null,{"className":"container flex h-14 items-center max-w-screen-xl mx-auto px-4 sm:px-6 lg:px-8","children":["$","$L7",null,{}]}]}],["$","main",null,{"className":"flex-1 container max-w-screen-xl mx-auto px-4 sm:px-6 lg:px-8 py-8","children":["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children"],"loading":"$undefined","loadingStyles":"$undefined","loadingScripts":"$undefined","hasLoading":false,"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":"404"}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],"notFoundStyles":[],"styles":null}]}]]}]}]}]}],null]],[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/d5495b0411c8fb4f.css","precedence":"next","crossOrigin":""}]],"$L8"]]]]
2:[["$","h1",null,{"children":"GPT-4 Visionを用いた視覚的理解の研究"}],"\n",["$","h2",null,{"children":"はじめに"}],"\n",["$","p",null,{"children":"GPT-4 Visionは、テキストと画像を組み合わせた理解を可能にする革新的なモデルです。\n本研究では、このモデルの視覚的理解能力と実世界での応用可能性について詳しく検討します。"}],"\n",["$","h2",null,{"children":"研究方法"}],"\n",["$","p",null,{"children":"我々は以下の3つの観点から評価を行いました："}],"\n",["$","ol",null,{"children":["\n",["$","li",null,{"children":"物体認識の精度"}],"\n",["$","li",null,{"children":"文脈理解の深さ"}],"\n",["$","li",null,{"children":"マルチモーダル推論能力"}],"\n"]}],"\n",["$","h2",null,{"children":"主な発見"}],"\n",["$","p",null,{"children":"研究の結果、以下の重要な知見が得られました："}],"\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":"GPT-4 Visionは従来のコンピュータビジョンモデルを大きく上回る文脈理解能力を示した"}],"\n",["$","li",null,{"children":"画像内の複数の要素間の関係性を理解し、適切な推論が可能"}],"\n",["$","li",null,{"children":"特に医療画像分析において、専門家レベルの判断能力を示す場面も"}],"\n"]}],"\n",["$","h2",null,{"children":"今後の展望"}],"\n",["$","p",null,{"children":"本研究の成果は、以下の分野での応用が期待されます："}],"\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":"医療診断支援"}],"\n",["$","li",null,{"children":"自動運転システム"}],"\n",["$","li",null,{"children":"セキュリティ監視"}],"\n",["$","li",null,{"children":"教育支援ツール"}],"\n"]}],"\n",["$","h2",null,{"children":"結論"}],"\n",["$","p",null,{"children":"GPT-4 Visionは、人工知能の視覚的理解において新たな地平を切り開く可能性を示しています。\n今後の研究開発により、さらなる進展が期待されます。"}]]
8:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"Herring's Portfolio"}],["$","meta","3",{"name":"description","content":"A portfolio showcasing my journey in AI and human intelligence research"}],["$","link","4",{"rel":"icon","href":"/favicon.ico","type":"image/x-icon","sizes":"16x16"}],["$","meta","5",{"name":"next-size-adjust"}]]
1:null
